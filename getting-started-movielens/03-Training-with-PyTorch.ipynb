{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_merlin_getting-started-movielens-03-training-with-pytorch/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Getting Started MovieLens: Training with PyTorch\n",
    "\n",
    "This notebook is created using the latest stable [merlin-pytorch-training](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-pytorch-training/tags) container.\n",
    "\n",
    "## Overview\n",
    "\n",
    "We observed that PyTorch training pipelines can be slow as the dataloader is a bottleneck. The native dataloader in PyTorch randomly sample each item from the dataset, which is very slow. In our experiments, we are able to speed-up existing PyTorch pipelines using a highly optimized dataloader.<br><br>\n",
    "\n",
    "Applying deep learning models to recommendation systems faces unique challenges in comparison to other domains, such as computer vision and natural language processing. The datasets and common model architectures have unique characteristics, which require custom solutions. Recommendation system datasets have terabytes in size with billion examples but each example is represented by only a few bytes. For example, the [Criteo CTR dataset](https://ailab.criteo.com/download-criteo-1tb-click-logs-dataset/), the largest publicly available dataset, is 1.3TB with 4 billion examples. The model architectures have normally large embedding tables for the users and items, which do not fit on a single GPU. You can read more in our [blogpost](https://medium.com/nvidia-merlin/why-isnt-your-recommender-system-training-faster-on-gpu-and-what-can-you-do-about-it-6cb44a711ad4).\n",
    "\n",
    "### Learning objectives\n",
    "\n",
    "This notebook explains, how to use the NVTabular dataloader to accelerate PyTorch training.\n",
    "\n",
    "1. Use **NVTabular dataloader** with PyTorch\n",
    "2. Leverage **multi-hot encoded input features**\n",
    "\n",
    "### MovieLens25M\n",
    "\n",
    "The [MovieLens25M](https://grouplens.org/datasets/movielens/25m/) is a popular dataset for recommender systems and is used in academic publications. The dataset contains 25M movie ratings for 62,000 movies given by 162,000 users. Many projects use only the user/item/rating information of MovieLens, but the original dataset provides metadata for the movies, as well. For example, which genres a movie has. Although we may not improve state-of-the-art results with our neural network architecture, the purpose of this notebook is to explain how to integrate multi-hot categorical features into a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NVTabular dataloader for PyTorch\n",
    "\n",
    "We’ve identified that the dataloader is one bottleneck in deep learning recommender systems when training pipelines with PyTorch. The dataloader cannot prepare the next batch fast enough, so and therefore, the GPU is not utilized. \n",
    "\n",
    "As a result, we developed a highly customized tabular dataloader for accelerating existing pipelines in PyTorch.  NVTabular dataloader’s features are:\n",
    "\n",
    "- removing bottleneck of item-by-item dataloading\n",
    "- enabling larger than memory dataset by streaming from disk\n",
    "- reading data directly into GPU memory and remove CPU-GPU communication\n",
    "- preparing batch asynchronously in GPU to avoid CPU-GPU communication\n",
    "- supporting commonly used .parquet format for efficient data format\n",
    "- easy integration into existing PyTorch pipelines by using similar API than the native one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External dependencies\n",
    "import os\n",
    "import gc\n",
    "import glob\n",
    "import pandas as pd\n",
    "import nvtabular as nvt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our base directory, containing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "dotenv.load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_DATA_DIR = os.environ.get(\n",
    "#     \"INPUT_DATA_DIR\", os.path.expanduser(\"~/nvt-examples/movielens/data/\")\n",
    "# )\n",
    "\n",
    "# DATASET_NAME = \"ml-1m\"\n",
    "# DATASET_NAME = \"ml-25m\"\n",
    "DATASET_NAME = os.getenv(\"DATASET_NAME\")\n",
    "# INPUT_DATA_DIR = \"/Users/nelsonlin/Desktop/data/movielens\"\n",
    "INPUT_DATA_DIR = os.getenv(\"INPUT_DATA_DIR\")\n",
    "INPUT_DATA_DIR = os.path.join(INPUT_DATA_DIR,DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the data schema and differentiate between single-hot and multi-hot categorical features. Note, that we do not have any numerical input features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024 * 32  # Batch Size\n",
    "CATEGORICAL_COLUMNS = [\"userId\", \"movieId\"]  # Single-hot\n",
    "CATEGORICAL_MH_COLUMNS = [\"genres\"]  # Multi-hot\n",
    "NUMERIC_COLUMNS = []\n",
    "\n",
    "# Output from ETL-with-NVTabular\n",
    "TRAIN_PATHS = sorted(glob.glob(os.path.join(INPUT_DATA_DIR, \"train\", \"*.parquet\")))\n",
    "VALID_PATHS = sorted(glob.glob(os.path.join(INPUT_DATA_DIR, \"valid\", \"*.parquet\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35987</td>\n",
       "      <td>9</td>\n",
       "      <td>[3, 1, 14]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>143647</td>\n",
       "      <td>62</td>\n",
       "      <td>[5, 13, 10, 2, 9]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57269</td>\n",
       "      <td>3</td>\n",
       "      <td>[2, 8, 1, 4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13803</td>\n",
       "      <td>17</td>\n",
       "      <td>[3, 5]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47329</td>\n",
       "      <td>47</td>\n",
       "      <td>[5, 2, 9]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000071</th>\n",
       "      <td>139906</td>\n",
       "      <td>1035</td>\n",
       "      <td>[1, 7, 4]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000072</th>\n",
       "      <td>391</td>\n",
       "      <td>2481</td>\n",
       "      <td>[1, 14]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000073</th>\n",
       "      <td>84805</td>\n",
       "      <td>85</td>\n",
       "      <td>[3, 5, 2, 8]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000074</th>\n",
       "      <td>66030</td>\n",
       "      <td>7</td>\n",
       "      <td>[3, 5, 7, 4]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000075</th>\n",
       "      <td>102990</td>\n",
       "      <td>6</td>\n",
       "      <td>[3, 5, 7]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000076 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          userId  movieId             genres  rating\n",
       "0          35987        9         [3, 1, 14]     1.0\n",
       "1         143647       62  [5, 13, 10, 2, 9]     1.0\n",
       "2          57269        3       [2, 8, 1, 4]     0.0\n",
       "3          13803       17             [3, 5]     1.0\n",
       "4          47329       47          [5, 2, 9]     1.0\n",
       "...          ...      ...                ...     ...\n",
       "20000071  139906     1035          [1, 7, 4]     1.0\n",
       "20000072     391     2481            [1, 14]     1.0\n",
       "20000073   84805       85       [3, 5, 2, 8]     0.0\n",
       "20000074   66030        7       [3, 5, 7, 4]     0.0\n",
       "20000075  102990        6          [3, 5, 7]     1.0\n",
       "\n",
       "[20000076 rows x 4 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(TRAIN_PATHS[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we used NVTabular for ETL and stored the workflow to disk. We can load the NVTabular workflow to extract important metadata for our training pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/nelsonlin/Desktop/data/movielens/ml-25m'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = nvt.Workflow.load(os.path.join(INPUT_DATA_DIR, \"workflow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The embedding table shows the cardinality of each categorical variable along with its associated embedding size. Each entry is of the form `(cardinality, embedding_size)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<merlin.dag.graph.Graph at 0x4e4d8d850>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proc.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': (162542, 512), 'movieId': (56604, 512)}, {'genres': (21, 16)})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_TABLE_SHAPES, MH_EMBEDDING_TABLE_SHAPES = nvt.ops.get_embedding_sizes(proc)\n",
    "EMBEDDING_TABLE_SHAPES, MH_EMBEDDING_TABLE_SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': (162542, 512), 'movieId': (56604, 512)}"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_TABLE_SHAPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'genres': (21, 16)}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MH_EMBEDDING_TABLE_SHAPES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing NVTabular Dataloader for PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import PyTorch and the NVTabular dataloader for PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from nvtabular.loader.torch import TorchAsyncItr, DLDataLoader\n",
    "from nvtabular.framework_utils.torch.models import Model\n",
    "from nvtabular.framework_utils.torch.utils import process_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take a look on our dataloader and how the data is represented as tensors. The NVTabular dataloaders are initialized as usual and we specify both single-hot and multi-hot categorical features as cats. The dataloader can automatically recognize the single/multi-hot columns and represent them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonlin/miniforge3/envs/torch/lib/python3.8/site-packages/merlin/io/dataset.py:253: UserWarning: Initializing an NVTabular Dataset in CPU mode.This is an experimental feature with extremely limited support!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TorchAsyncItr(\n",
    "    nvt.Dataset(TRAIN_PATHS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    cats=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    conts=NUMERIC_COLUMNS,\n",
    "    labels=[\"rating\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DLDataLoader(\n",
    "    train_dataset, batch_size=None, collate_fn=lambda x: x, pin_memory=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<nvtabular.loader.torch.DLDataLoader at 0x3de5517c0>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataset = TorchAsyncItr(\n",
    "    nvt.Dataset(VALID_PATHS),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    cats=CATEGORICAL_COLUMNS + CATEGORICAL_MH_COLUMNS,\n",
    "    conts=NUMERIC_COLUMNS,\n",
    "    labels=[\"rating\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = DLDataLoader(\n",
    "    valid_dataset, batch_size=None, collate_fn=lambda x: x, pin_memory=False, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate a batch and take a look on the input features.<br><br>\n",
    "The single-hot categorical features (`userId` and `movieId`) have a shape of `(32768, 1)`, which is the batch size (as usually). For the multi-hot categorical feature `genres`, we receive two Tensors `genres__values` and `genres__nnzs`.<br><br>\n",
    "- `values` are the actual data, containing the genre IDs. Note that the Tensor has more values than the batch_size. The reason is, that one datapoint in the batch can contain more than one genre (multi-hot).<br>\n",
    "- `nnzs` are a supporting Tensor, describing how many genres are associated with each datapoint in the batch.<br><br>\n",
    "For example,\n",
    "- if the first two values in `nnzs` is `0`, `2`, then the first 2 values (0, 1) in `values` are associated with the first datapoint in the batch (movieId/userId).<br>\n",
    "- if the next value in `nnzs` is `6`, then the 3rd, 4th and 5th value in `values` are associated with the second datapoint in the batch (continuing after the previous value stopped).<br> \n",
    "- if the third value in `nnzs` is `7`, then the 6th value in `values` are associated with the third datapoint in the batch. \n",
    "- and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))\n",
    "# batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'genres': (tensor([ 3,  1, 14,  ...,  3,  4,  2]),\n",
       "   tensor([[    0],\n",
       "           [    3],\n",
       "           [    8],\n",
       "           ...,\n",
       "           [88770],\n",
       "           [88773],\n",
       "           [88775]])),\n",
       "  'userId': tensor([[ 35987],\n",
       "          [143647],\n",
       "          [ 57269],\n",
       "          ...,\n",
       "          [ 20368],\n",
       "          [ 76978],\n",
       "          [  5542]]),\n",
       "  'movieId': tensor([[  9],\n",
       "          [ 62],\n",
       "          [  3],\n",
       "          ...,\n",
       "          [261],\n",
       "          [564],\n",
       "          [ 50]])},\n",
       " tensor([1., 1., 0.,  ..., 0., 0., 1.]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['genres', 'userId', 'movieId'])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,nnzs =  X['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3,  1, 14,  ...,  3,  4,  2])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88776])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"expanded\"\"\"\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0],\n",
       "        [    3],\n",
       "        [    8],\n",
       "        ...,\n",
       "        [88770],\n",
       "        [88773],\n",
       "        [88775]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"index\"\"\"\n",
    "nnzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 1])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnzs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 35987],\n",
       "        [143647],\n",
       "        [ 57269],\n",
       "        ...,\n",
       "        [ 20368],\n",
       "        [ 76978],\n",
       "        [  5542]])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['userId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 1])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['userId'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 1])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['movieId'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 1])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['movieId'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X_cat_multihot` is a tuple of two Tensors. For the multi-hot categorical feature `genres`, we receive two Tensors `values` and `nnzs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3,  1, 14,  ...,  3,  4,  2]),\n",
       " tensor([[    0],\n",
       "         [    3],\n",
       "         [    8],\n",
       "         ...,\n",
       "         [88770],\n",
       "         [88773],\n",
       "         [88775]]))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_multihot = batch[0]['genres']\n",
    "X_cat_multihot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([88776])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_multihot[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32768, 1])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_multihot[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As each datapoint can have a different number of genres, it is more efficient to represent the genres as two flat tensors: One with the actual values (`values`) and one with the length for each datapoint (`nnzs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del batch\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Neural Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implemented a simple PyTorch architecture.\n",
    "\n",
    "* Single-hot categorical features are fed into an Embedding Layer\n",
    "* Each value of a multi-hot categorical features is fed into an Embedding Layer and the multiple Embedding outputs are combined via summing\n",
    "* The output of the Embedding Layers are concatenated\n",
    "* The concatenated layers are fed through multiple feed-forward layers (Dense Layers, BatchNorm with ReLU activations)\n",
    "\n",
    "You can see more details by checking out the implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the model. `EMBEDDING_TABLE_SHAPES` needs to be a Tuple representing the cardinality for single-hot and multi-hot input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId', 'movieId']"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CATEGORICAL_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'userId': (162542, 512), 'movieId': (56604, 512)}, {'genres': (21, 16)})"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMBEDDING_TABLE_SHAPES_TUPLE = (\n",
    "    {\n",
    "        CATEGORICAL_COLUMNS[0]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_COLUMNS[0]],\n",
    "        CATEGORICAL_COLUMNS[1]: EMBEDDING_TABLE_SHAPES[CATEGORICAL_COLUMNS[1]],\n",
    "    },\n",
    "    {CATEGORICAL_MH_COLUMNS[0]: MH_EMBEDDING_TABLE_SHAPES[CATEGORICAL_MH_COLUMNS[0]]},\n",
    ")\n",
    "EMBEDDING_TABLE_SHAPES_TUPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    embedding_table_shapes=EMBEDDING_TABLE_SHAPES_TUPLE,\n",
    "    num_continuous=0,\n",
    "    emb_dropout=0.0,\n",
    "    layer_hidden_dims=[128, 128, 128],\n",
    "    layer_dropout_rates=[0.0, 0.0, 0.0],\n",
    ").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (initial_cat_layer): ConcatenatedEmbeddings(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): Embedding(162542, 512)\n",
       "      (1): Embedding(56604, 512)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (mh_cat_layer): MultiHotEmbeddings(\n",
       "    (embedding_layers): ModuleList(\n",
       "      (0): EmbeddingBag(21, 16, mode=sum)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "  )\n",
       "  (initial_cont_layer): BatchNorm1d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (layers): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=1040, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `process_epoch` function to train and validate our model. It iterates over the dataset and calculates as usually the loss and optimizer step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonlin/miniforge3/envs/torch/lib/python3.8/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 610\n",
      "Total batches: 152\n",
      "Epoch 00. Train loss: 0.1910. Valid loss: 0.1688. AUC:0.807453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonlin/miniforge3/envs/torch/lib/python3.8/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 610\n",
      "Total batches: 152\n",
      "Epoch 01. Train loss: 0.1636. Valid loss: 0.1661. AUC:0.816713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonlin/miniforge3/envs/torch/lib/python3.8/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 610\n",
      "Total batches: 152\n",
      "Epoch 02. Train loss: 0.1554. Valid loss: 0.1680. AUC:0.817878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonlin/miniforge3/envs/torch/lib/python3.8/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 610\n",
      "Total batches: 152\n",
      "Epoch 03. Train loss: 0.1451. Valid loss: 0.1757. AUC:0.813898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nelsonlin/miniforge3/envs/torch/lib/python3.8/site-packages/torch/amp/autocast_mode.py:204: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total batches: 610\n",
      "Total batches: 152\n",
      "Epoch 04. Train loss: 0.1340. Valid loss: 0.1819. AUC:0.807674\n",
      "run_time: 304.9971218109131 - rows: 11460 - epochs: 5 - dl_thru: 37.57412506700563\n",
      "CPU times: user 1h 24min 50s, sys: 34min 8s, total: 1h 58min 59s\n",
      "Wall time: 25min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import time\n",
    "EPOCHS = 5\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time()\n",
    "    train_loss, y_pred, y = process_epoch(train_loader,\n",
    "                                          model,\n",
    "                                          train=True,\n",
    "                                          optimizer=optimizer)\n",
    "    valid_loss, y_pred, y = process_epoch(valid_loader,\n",
    "                                          model,\n",
    "                                          train=False)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y.numpy(), y_pred.numpy(), pos_label=1)\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    print(f\"Epoch {epoch:02d}. Train loss: {train_loss:.4f}. Valid loss: {valid_loss:.4f}. AUC:{auc:4f}\")\n",
    "t_final = time() - start\n",
    "total_rows = train_dataset.num_rows_processed + valid_dataset.num_rows_processed\n",
    "print(\n",
    "    f\"run_time: {t_final} - rows: {total_rows * EPOCHS} - epochs: {EPOCHS} - dl_thru: {(total_rows * EPOCHS) / t_final}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "merlin": {
   "containers": [
    "nvcr.io/nvidia/merlin/merlin-pytorch-training:latest"
   ]
  },
  "vscode": {
   "interpreter": {
    "hash": "0eb94250e807a4b8afb9c3a175190453ecbfb9c88221c7c39a57fa462e93c843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
